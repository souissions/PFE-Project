# graph/graphFlow.py

import tools
import traceback
from langchain_core.messages import HumanMessage
from utils import load_llm, load_specialist_list
from state import AgentState
import prompts  # Assuming you have predefined prompts for LLM interaction
from langchain_core.chains import LLMChain
import base64 # Needed for image encoding
from tools import *


# --- Load the LLM and other necessary components ---
llm = load_llm()  # Initialize LLM here
intent_chain = LLMChain(llm=llm, prompt=prompts.intent_classifier_prompt)  # Assuming the intent classifier prompt is defined in prompts
followup_chain = LLMChain(llm=llm, prompt=prompts.followup_prompt)  # Assuming the follow-up prompt is defined in prompts

# --- Node Function Definitions ---

def classify_intent_node(state: AgentState) -> dict:
    """Classifies the user's intent considering text and optional image."""
    print("\n--- Node: classify_intent ---")
    
    if not intent_chain:
        print("Error: Intent chain not available.")
        return {"user_intent": "OFF_TOPIC"}

    latest_query = state.get('user_query', '')
    llm_input_content = [{"type": "text", "text": prompts.intent_classifier_prompt.format(user_query=latest_query)}]

    if 'uploaded_image_bytes' in state and state['uploaded_image_bytes']:
        try:
            encoded_image = base64.b64encode(state['uploaded_image_bytes']).decode('utf-8')
            llm_input_content.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{encoded_image}"}})
        except Exception as e_enc:
            print(f"Warning: Could not encode image for intent check: {e_enc}")

    # Call LLM for intent classification
    response = intent_chain.invoke({"content": llm_input_content})
    intent = response.get('text', 'OFF_TOPIC').strip()

    return {"user_intent": intent}


def gather_symptoms_node(state: AgentState) -> dict:
    """Gathers symptoms and checks if enough information has been provided."""
    print("\n--- Node: gather_symptoms ---")
    current_symptoms = state.get('accumulated_symptoms', '')
    latest_query = state.get('user_query', '')
    new_symptoms = f"{current_symptoms}\nUser: {latest_query}" if latest_query else current_symptoms

    # Check if enough symptoms have been gathered
    sufficient_info = True  # Logic for sufficiency check (adjust if necessary)

    if not sufficient_info:
        # Ask for follow-up question if more symptoms are required
        followup_input = prompts.followup_prompt.format(accumulated_symptoms=new_symptoms)
        response = followup_chain.invoke({"content": followup_input})
        followup_question = response.get('text', "Please provide more details.")
        return {"final_response": followup_question}

    return {"accumulated_symptoms": new_symptoms}


def check_triage_relevance_node(state: AgentState) -> dict:
    """Checks if the accumulated symptoms are medically relevant."""
    print("\n--- Node: check_triage_relevance ---")
    symptoms = state.get('accumulated_symptoms', '')

    # Perform a relevance check (adjust as per your logic)
    is_relevant = True  # Adjust based on relevance check result

    return {"is_relevant": is_relevant}


def handle_info_request_node(state: AgentState) -> dict:
    """Handles medical information requests."""
    print("\n--- Node: handle_info_request ---")
    query = state.get('user_query', '')
    if not query:
        return {"final_response": "No query provided."}

    # Perform RAG, ICD matching, and generate an answer
    context = tools.retrieve_relevant_documents.invoke({"user_symptoms": query})
    icd_codes = tools.match_relevant_icd_codes.invoke({"user_symptoms": query})

    response_content = f"Context: {context}\nICD Codes: {icd_codes}"
    return {"final_response": response_content}


def perform_final_analysis_node(state: AgentState) -> dict:
    """Final analysis using RAG and ICD code matching."""
    print("\n--- Node: perform_final_analysis ---")
    symptoms = state.get('accumulated_symptoms', '')
    context = tools.retrieve_relevant_documents.invoke({"user_symptoms": symptoms})
    icd_codes = tools.match_relevant_icd_codes.invoke({"user_symptoms": symptoms})

    return {"rag_context": context, "matched_icd_codes": icd_codes}


def evaluate_explanation_node(state: AgentState) -> dict:
    """Evaluates the explanation generated by the agent."""
    print("\n--- Node: evaluate_explanation ---")
    explanation = state.get('initial_explanation', '')

    # Evaluate the explanation using LLM
    critique = "OK"  # Placeholder for the critique result (adjust as needed)

    return {"evaluator_critique": critique}


def refine_explanation_node(state: AgentState) -> dict:
    """Refines the explanation based on evaluation critique."""
    print("\n--- Node: refine_explanation ---")
    explanation = state.get('initial_explanation', '')
    critique = state.get('evaluator_critique', 'OK')

    if critique == "OK":
        return {"loop_count": state.get('loop_count', 0) + 1}

    # If refinement is needed, pass to LLM for refinement
    refined_explanation = "Refined explanation"  # Adjust as needed
    return {"initial_explanation": refined_explanation, "loop_count": state.get('loop_count', 0) + 1}
